{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例 06: 爬蟲實戰練習 (15~20 mins)\n",
    "接下來就是大家今天的實戰練習時間囉! 這邊的練習會希望大家能夠自行透過觀察網頁，把目標網頁的資訊爬取回來，並存成 CSV 以利後續的分析。\n",
    "\n",
    "今天大家要爬取的目標網頁共有兩個\n",
    "1. [台北票房觀測站 - 年度排名 (2016+2017)](http://www.taipeibo.com/year/2017) 的票房資料\n",
    "2. [Yahoo電影評論](https://tw.movies.yahoo.com/movieinfo_main.html/id=6664)，包含電影名稱、評論文字、評論星等\n",
    "\n",
    "以下的範例 code 會示範如何抓下[年度周末冠軍](http://www.taipeibo.com/yearly)的網頁資訊，各位強者同學們如果已經躍躍欲試的話可以跳過以下的提示 code，直接開始練習囉!\n",
    "\n",
    "如果真的沒有頭緒的話可以參考以下的 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "response = requests.get(\"http://www.taipeibo.com/yearly\") # 取得網頁\n",
    "response.encoding =\"utf-8\" # 設定 encoding = 'utf-8' (如果不設定，會發生甚麼事情呢?)\n",
    "soup = BeautifulSoup(response.text, 'lxml') # 用 BS4 parse 網頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr class=\"tb-top\">\n",
      "<th>週次</th>\n",
      "<th>日期</th>\n",
      "<th>週末票房總和</th>\n",
      "<th>漲跌幅</th>\n",
      "<th>冠軍片名</th>\n",
      "<th>英文片名</th>\n",
      "<th class=\"import\">週末票房冠軍</th>\n",
      "<th>冠軍比例*</th>\n",
      "</tr>, <tr>\n",
      "<td class=\"list-h1\" data-th=\"週次\">31</td>\n",
      "<td class=\"list-h2\" data-th=\"日期\">08/05 - 06</td>\n",
      "<td class=\"list-h3\" data-th=\"週末票房總和\">29,901,738</td>\n",
      "<td class=\"t-up list-h4\" data-th=\"漲跌幅\">+13.3%</td>\n",
      "<td class=\"list-h5\" data-th=\"冠軍片名\">模犯生</td>\n",
      "<td class=\"list-h6\" data-th=\"英文片名\">Bad Genius</td>\n",
      "<td class=\"import list-h7\" data-th=\"周末票房冠軍\">5,562,901</td>\n",
      "<td class=\"list-h8\" data-th=\"冠軍比例\">18.60%</td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "# 在觀察網頁之後，發現表格中每一列的文字都躲在 tr 標籤底下，並用 td 包起來。\n",
    "all_rows = soup.table.find_all(\"tr\") # 找出所有 tr 標籤，並存成 list\n",
    "print(all_rows[:2]) # 印出前兩筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_name_tag = all_rows[0] # 標題名稱的標籤就是 all_rows 的第一筆資料 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['週次', '日期', '週末票房總和', '漲跌幅', '冠軍片名', '英文片名', '週末票房冠軍', '冠軍比例*']\n"
     ]
    }
   ],
   "source": [
    "print([text for text in column_name_tag.stripped_strings]) # 把使用 strpped_strings 取出來的值印出來，可以看到就是我們想要的標題\n",
    "column_name = [text for text in column_name_tag.stripped_strings] # 把這些標題存成 column_name 這個變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>週次</th>\n",
       "      <th>日期</th>\n",
       "      <th>週末票房總和</th>\n",
       "      <th>漲跌幅</th>\n",
       "      <th>冠軍片名</th>\n",
       "      <th>英文片名</th>\n",
       "      <th>週末票房冠軍</th>\n",
       "      <th>冠軍比例*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [週次, 日期, 週末票房總和, 漲跌幅, 冠軍片名, 英文片名, 週末票房冠軍, 冠軍比例*]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.DataFrame(columns = column_name) # 建立一個空的 DataFrame，標題等於剛剛抓下來的 column_name\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', '08/05 - 06', '29,901,738', '+13.3%', '模犯生', 'Bad Genius', '5,562,901', '18.60%']\n",
      "['30', '07/29 - 30', '26,392,639', '-28.2%', '敦克爾克大行動', 'Dunkirk', '6,008,394', '22.77%']\n",
      "['29', '07/22 - 23', '36,766,707', '-11.5%', '敦克爾克大行動', 'Dunkirk', '11,143,938', '30.31%']\n",
      "['28', '07/15 - 16', '41,532,307', '-1.7%', '猩球崛起：終極決戰', 'War for the Planet of the Apes', '13,670,006', '32.91%']\n",
      "['27', '07/08 - 09', '42,249,157', '+26.7%', '蜘蛛人：返校日', 'Spider-Man: Homecoming', '25,573,718', '60.53%']\n",
      "['26', '07/01 - 02', '33,342,350', '+1.7%', '神偷奶爸3', 'Despicable Me 3', '13,361,083', '40.07%']\n",
      "['25', '06/24 - 25', '32,798,987', '+7.1%', '變形金剛5：最終騎士', 'Transformers: The Last Knight', '18,392,933', '56.08%']\n",
      "['24', '06/17 - 18', '30,627,483', '-35.8%', '神鬼傳奇', 'The Mummy', '11,822,715', '38.60%']\n",
      "['23', '06/10 - 11', '47,690,608', '+16.1%', '神鬼傳奇', 'The Mummy', '25,342,873', '53.14%']\n",
      "['22', '06/03 - 04', '41,065,920', '+2.0%', '神力女超人', 'Wonder Woman', '22,552,902', '54.92%']\n",
      "['21', '05/27 - 28', '40,249,069', '+72.1%', '加勒比海盜 神鬼奇航：死無對證', 'Pirates of the Caribbean: Dead Men Tell No Tales', '19,807,313', '49.21%']\n",
      "['20', '05/20 - 21', '23,391,591', '-12.5%', '異形：聖約', 'Alien: Covenant', '4,426,175', '18.92%']\n",
      "['19', '05/13 - 14', '26,723,984', '+2.1%', '異形：聖約', 'Alien: Covenant', '7,948,394', '29.74%']\n",
      "['18', '05/06 - 07', '26,164,753', '-33.3%', '星際異攻隊2', 'Guardians of the Galaxy Vol. 2', '6,389,709', '24.42%']\n",
      "['17', '04/29 - 30', '39,251,412', '-13.0%', '星際異攻隊2', 'Guardians of the Galaxy Vol. 2', '14,394,979', '36.67%']\n",
      "['16', '04/22 - 23', '45,129,299', '-21.0%', '玩命關頭8', 'Fast & Furious 8', '25,495,070', '56.49%']\n",
      "['15', '04/15 - 16', '57,119,679', '+101.8%', '玩命關頭8', 'Fast & Furious 8', '43,723,394', '76.55%']\n",
      "['14', '04/08 - 09', '28,305,387', '-27.3%', '我和我的冠軍女兒', 'Dangal', '5,320,460', '18.80%']\n",
      "['13', '04/01 - 02', '38,910,589', '-1.3%', '攻殼機動隊', 'Ghost in the Shell', '9,109,929', '23.41%']\n",
      "['12', '03/25 - 26', '39,433,059', '-3.9%', '美女與野獸', 'Beauty and the Beast', '13,716,273', '34.78%']\n",
      "['11', '03/18 - 19', '41,042,742', '-3.3%', '美女與野獸', 'Beauty and the Beast', '18,479,670', '45.03%']\n",
      "['10', '03/11 - 12', '42,432,794', '+22.1%', '金剛：骷髏島', 'Kong: Skull Island', '22,498,616', '53.02%']\n",
      "['9', '03/04 - 05', '34,742,444', '+0.2%', '羅根', 'Logan', '19,151,017', '55.12%']\n",
      "['8', '02/25 - 26', '34,686,509', '+22.6%', '為了與你相遇', \"A Dog's Purpose\", '6,496,370', '18.73%']\n",
      "['7', '02/18 - 19', '28,289,101', '-24.3%', '分裂', 'Split', '5,254,230', '18.57%']\n",
      "['6', '02/11 - 12', '37,347,272', '+0.0%', '分裂', 'Split', '7,854,274', '21.03%']\n",
      "['5', '02/04 - 05', '37,341,953', '-11.9%', '分裂', 'Split', '12,126,104', '32.47%']\n",
      "['4', '01/28 - 29', '42,383,866', '+65.6%', '惡靈古堡：最終章', 'Resident Evil: The Final Chapter', '14,190,341', '33.48%']\n",
      "['3', '01/21 - 22', '25,592,268', '+5.7%', '限制級戰警：重返極限', 'xXx: Return of Xander Cage', '12,422,855', '48.54%']\n",
      "['2', '01/14 - 15', '24,201,453', '-0.6%', '樂來越愛你', 'La La Land', '3,633,570', '15.01%']\n",
      "['1', '01/07 - 08', '24,340,462', '-46.5%', '長城', 'The Great Wall', '4,877,021', '20.04%']\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.DataFrame(columns = column_name) # 第一個 row 為標題\n",
    "for i, row in enumerate(all_rows[1:]): # 從第二個 row 開始 iterate (因為第一個 row 是標題)\n",
    "    data_want = [s for s in row.stripped_strings]\n",
    "    print(data_want)\n",
    "    movie_df.loc[i] = data_want # 設定 DataFrame 的第 i 個 row 是我們抓下來的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>週次</th>\n",
       "      <th>日期</th>\n",
       "      <th>週末票房總和</th>\n",
       "      <th>漲跌幅</th>\n",
       "      <th>冠軍片名</th>\n",
       "      <th>英文片名</th>\n",
       "      <th>週末票房冠軍</th>\n",
       "      <th>冠軍比例*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>08/05 - 06</td>\n",
       "      <td>29,901,738</td>\n",
       "      <td>+13.3%</td>\n",
       "      <td>模犯生</td>\n",
       "      <td>Bad Genius</td>\n",
       "      <td>5,562,901</td>\n",
       "      <td>18.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>07/29 - 30</td>\n",
       "      <td>26,392,639</td>\n",
       "      <td>-28.2%</td>\n",
       "      <td>敦克爾克大行動</td>\n",
       "      <td>Dunkirk</td>\n",
       "      <td>6,008,394</td>\n",
       "      <td>22.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>07/22 - 23</td>\n",
       "      <td>36,766,707</td>\n",
       "      <td>-11.5%</td>\n",
       "      <td>敦克爾克大行動</td>\n",
       "      <td>Dunkirk</td>\n",
       "      <td>11,143,938</td>\n",
       "      <td>30.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>07/15 - 16</td>\n",
       "      <td>41,532,307</td>\n",
       "      <td>-1.7%</td>\n",
       "      <td>猩球崛起：終極決戰</td>\n",
       "      <td>War for the Planet of the Apes</td>\n",
       "      <td>13,670,006</td>\n",
       "      <td>32.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>07/08 - 09</td>\n",
       "      <td>42,249,157</td>\n",
       "      <td>+26.7%</td>\n",
       "      <td>蜘蛛人：返校日</td>\n",
       "      <td>Spider-Man: Homecoming</td>\n",
       "      <td>25,573,718</td>\n",
       "      <td>60.53%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   週次          日期      週末票房總和     漲跌幅       冠軍片名  \\\n",
       "0  31  08/05 - 06  29,901,738  +13.3%        模犯生   \n",
       "1  30  07/29 - 30  26,392,639  -28.2%    敦克爾克大行動   \n",
       "2  29  07/22 - 23  36,766,707  -11.5%    敦克爾克大行動   \n",
       "3  28  07/15 - 16  41,532,307   -1.7%  猩球崛起：終極決戰   \n",
       "4  27  07/08 - 09  42,249,157  +26.7%    蜘蛛人：返校日   \n",
       "\n",
       "                             英文片名      週末票房冠軍   冠軍比例*  \n",
       "0                      Bad Genius   5,562,901  18.60%  \n",
       "1                         Dunkirk   6,008,394  22.77%  \n",
       "2                         Dunkirk  11,143,938  30.31%  \n",
       "3  War for the Planet of the Apes  13,670,006  32.91%  \n",
       "4          Spider-Man: Homecoming  25,573,718  60.53%  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head() # 大功告成! 就只剩把 DataFrame 存起來就好，那接下來就請聰明的各位來練習一下囉!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df.to_csv(\"csv_results/movie_df.csv\", index = False, encoding=\"utf-8\") # 把 DataFrame 存起來，那接下來就請聰明的各位來練習一下囉!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 06-1: 台北票房觀測站爬蟲\n",
    "請將 2016 [年度排名](http://www.taipeibo.com/year/2016)與 2017 的[年度排名](http://www.taipeibo.com/year/2017) 網頁分別抓下來 並合併後存成一個 csv 檔案，請將檔案儲存至 csv_results/ 這個資料夾底下\n",
    "\n",
    "Hint\n",
    "* DF = df1.append(df2) \n",
    "這段 code 可以把兩個 DataFrame 垂直合併成一個新的 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 練習 06-2: Yahoo 電影評論爬蟲 (20~25 mins)\n",
    "\n",
    "請仔細觀察 Yahoo 電影評論的網頁，您將需要把任何一部在票房排行榜上您喜歡的電影的\n",
    "1. 電影名稱 \n",
    "2. 每條評論文字\n",
    "3. 每條評論星等\n",
    "\n",
    "都爬取下來並存成 CSV，請將檔案儲存至 csv_results/ 這個資料夾底下，如果沒有頭緒要抓哪部，可以試試[玩命關頭8](https://tw.movies.yahoo.com/movieinfo_review.html/id=6664)\n",
    "\n",
    "\n",
    "這題的可能會稍微比較有挑戰一些，如果卡住請大家不要灰心，可以與旁邊的同學討論或是隨時舉手請問助教，以下是一些提示\n",
    "1. 請先觀察每一頁評論的網址 (URL) 都是甚麼，有沒有甚麼特殊的規律?\n",
    "2. 如果要抓取總共有幾頁評論，要怎麼抓取哪個標籤呢?\n",
    "3. 評論文字都藏在哪些標籤裡?\n",
    "4. 評論有幾顆星星好像找不到? 試試找其他方向，說不定在意想不到的地方喔\n",
    "5. 如何把每一頁抓完的評論 list 合併成一個 大 list? 可以使用 big_list.extend(small_list)，可以把許多小 list merge 成一個大的 list\n",
    "\n",
    "**如果真的沒有頭緒的話，可以先把問題簡化，嘗試看看把其中一頁的評論抓下來試試看!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "以下 codes 僅供參考，會將所有票房排行榜 200 部電影的 yahoo 電影評論全部抓下來，並存成 CSV (請不要在今天執行，以免影響網路速度與 yahoo 電影流量)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 把所有 yahoo 電影的 id 讀進來\n",
    "with open(\"data/all_movie_id.json\", 'r', encoding=\"utf-8\") as f:\n",
    "    movie_id = json.load(f)\n",
    "    \n",
    "movie_name_list = pd.read_csv(\"data/movies_box_office.csv\")[\"中文片名\"]\n",
    "success = []\n",
    "all_df = []\n",
    "for i, x in enumerate(movie_name_list):\n",
    "    print(\"開始爬取 \", i+1, \" :\" , x)\n",
    "    id = movie_id[x]\n",
    "    response = requests.get(\"https://tw.movies.yahoo.com/movieinfo_review.html/id=\" + str(id))\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    if soup.find(\"div\", {\"class\":\"page_numbox\"}) != None:\n",
    "        page = int(soup.find(\"div\", {\"class\":\"page_numbox\"}).find_all(\"a\")[-2].text)\n",
    "        \n",
    "        comment_all = []\n",
    "        star_all = []\n",
    "        comment_df = pd.DataFrame(columns =  [\"movie\", \"comments\", \"star\"])\n",
    "\n",
    "        for i in range(1, page):\n",
    "            response = requests.get(\"https://tw.movies.yahoo.com/movieinfo_review.html/id=\" + id + \"?sort=create_ts&order=desc&page=\" + str(i) )\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            comment = [x.find(\"span\").text for x in soup.find_all(\"div\", {\"class\":\"usercom_inner _c\"})]\n",
    "            comment_all.extend(comment)\n",
    "\n",
    "            star = [comment.find(\"input\", {\"name\":\"score\"})['value'] for comment in soup.find_all(\"div\", {\"class\":\"usercom_inner _c\"})]\n",
    "            star_all.extend(star)\n",
    "\n",
    "        movie_name = soup.find(\"div\", {\"class\":\"inform_title\"}).text\n",
    "        comment_df = pd.DataFrame({\"comments\":comment_all,\n",
    "                                   \"movie\":movie_name,\n",
    "                                  \"star\":star_all})\n",
    "        if len(comment_df)!= 0:\n",
    "            success.append(x) \n",
    "    else:\n",
    "        comment_all = []\n",
    "        star_all = []\n",
    "        comment_df = pd.DataFrame(columns =  [\"movie\", \"comments\", \"star\"])\n",
    "        \n",
    "        comment = [x.find(\"span\").text for x in soup.find_all(\"div\", {\"class\":\"usercom_inner _c\"})]\n",
    "        comment_all.extend(comment)\n",
    "\n",
    "        star = [comment.find(\"input\", {\"name\":\"score\"})['value'] for comment in soup.find_all(\"div\", {\"class\":\"usercom_inner _c\"})]\n",
    "        star_all.extend(star)\n",
    "\n",
    "        movie_name = soup.find(\"div\", {\"class\":\"inform_title\"}).text\n",
    "        comment_df = pd.DataFrame({\"comments\":comment_all,\n",
    "                                   \"movie\":movie_name,\n",
    "                                  \"star\":star_all})\n",
    "        if len(comment_df)!= 0:\n",
    "            success.append(x) \n",
    "    \n",
    "    all_df.append(comment_df)\n",
    "    \n",
    "movies_comments = pd.concat(all_df, axis=0)\n",
    "movies_comments.to_csv(\"csv_results/movies_comments_crawled.csv\", index = False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
