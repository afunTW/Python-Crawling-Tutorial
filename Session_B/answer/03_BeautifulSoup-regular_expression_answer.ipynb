{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION B: 爬蟲實戰與資料分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Session B 會用到的套件 (不包含資料分析部分)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 範例 03: BeautifulSoup + regular expression\n",
    "\n",
    "透過 BeautifulSoup 加上 regular expression ，能夠輕鬆的找出所有符合您規則的標籤、屬性或是內容。\n",
    "\n",
    "與 regular expression 的 **re.findall()** 不同在於，這邊必須使用 **re.compile**，如此一來 BeautifulSoup 就會知道您要使用 regular expression，並且回傳所有符合條件的標籤、屬性或是內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 萬年起手式\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "response = requests.get(\"https://jimmy15923.github.io/example_page\")\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <th>標頭 1 (table-header)</th>\n",
       " <th>標頭 2 (table-header)</th>\n",
       " <th>標頭 3 (table-header)</th>\n",
       " <th>標頭 4 (table-header)</th>\n",
       " </tr>, <tr>\n",
       " <td> 列2 欄1 </td>\n",
       " <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>\n",
       " <td>\n",
       " <a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n",
       " </td>\n",
       " <td>\n",
       " <a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>\n",
       " </td>\n",
       " </tr>, <td> 列2 欄1 </td>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>, <td>\n",
       " <a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n",
       " </td>, <td>\n",
       " <a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>\n",
       " </td>, <tr>\n",
       " <td value=\"5566\">列3 欄1 </td>\n",
       " <td>列3 欄2\n",
       " \t\t\t\t<ol>\n",
       " <li class=\"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\n",
       " <li> 第二個 li 標籤 </li>\n",
       " </ol>\n",
       " </td>\n",
       " <td>\n",
       " <a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\n",
       " </td>\n",
       " <td class=\"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>\n",
       " </tr>, <td value=\"5566\">列3 欄1 </td>, <td>列3 欄2\n",
       " \t\t\t\t<ol>\n",
       " <li class=\"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\n",
       " <li> 第二個 li 標籤 </li>\n",
       " </ol>\n",
       " </td>, <td>\n",
       " <a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\n",
       " </td>, <td class=\"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(re.compile(\"t(d|r)\"))  # 找出所有 td 或 tr 的標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"zzz\" id=\"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>,\n",
       " <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>,\n",
       " <li class=\"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>,\n",
       " <td class=\"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"\", {\"class\":re.compile(\"z+\")})    # 找出所有屬性為 class 且值包含至少一個 z 以上的標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['網頁名稱-python crawler', 'python_crawler', ' 列3 欄3 (資料協會-python 爬蟲實戰)', 'python_crawler']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(\"\", text = re.compile(\"python\")))  # 找出所有 text 內容包含 python 文字的標籤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 練習 03: BeautifulSoup + regular expression (8 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. [範例網頁中](https://jimmy15923.github.io/example_page)可以看到有許多超連結，請找出那些超連結的網址是以資料協會網站開頭的標籤(\"http://foundation.datasci.tw/...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>, <a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>]\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "response = requests.get(\"https://jimmy15923.github.io/example_page\")\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "print(soup.find_all(\"\",href = re.compile(\"http://foundation.datasci.tw/\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 請觀察[518 黃頁網](http://yp.518.com.tw/service-life.html?ctf=10)，並找出所有位在新北市的店家地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"comp_loca\">新北市 / 永和區 永亨路49號</li>, <li class=\"comp_loca\">新北市 / 板橋區 僑中一街124巷62-20號</li>, <li class=\"comp_loca\">新北市 / 板橋區 僑中一街124巷62-20號</li>, <li class=\"comp_loca\">新北市 / 板橋區 國光路39號</li>]\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "response = requests.get(\"https://jimmy15923.github.io/518\")\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "print(soup.find_all(\"li\",class_=\"comp_loca\", text = re.compile(\"新北\")))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
